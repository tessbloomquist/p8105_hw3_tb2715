---
title: "p8105_hw3_tb2715"
author: "Tess"
date: "10/5/2019"
output: gitbub_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(viridis)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

##Question 1
```{r}
library(p8105.datasets)
data("instacart") 

instacart = 
   janitor::clean_names(instacart) %>%
  drop_na()

#identify number of aisles
instacart %>%
  count(aisle_id) 
```

#arrange aisles by number of goods in an aisle
```{r}
instacart %>%
  group_by(aisle_id) %>%
  summarize(n_obs = n()) %>%
  arrange(desc(n_obs))
```

There are 134 aisles in this data set. Aisles 83, 24, 123, and 120 have the most items ordered from them in that respective order. 

#plot of aisles with more than 10,000 items. 
#Is there a better way to label?
```{r}
instacart %>%
  group_by(aisle_id) %>%
  summarize(n_obs = n()) %>% 
  filter(n_obs > 10000) %>%
  ggplot(aes(x = aisle_id, y = n_obs)) +
  geom_col() +
  scale_x_continuous(
    breaks = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130)) 

```

#table of the most popular items “baking ingredients”, “dog food care”, and “packaged vegetables fruits”
```{r}
instacart %>%
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>%
  group_by(aisle, product_name) %>%
  summarize(n_obs = n()) %>%
  group_by(aisle) %>%
  mutate(ranking = rank(-n_obs)) %>%
  filter(ranking <= 3) %>%
  arrange(ranking) %>%
  knitr::kable(digits = 1)

```

#table of the mean hour of the day when Pink Lady apples and Coffee are bought each day of the week
```{r}
instacart %>%
  filter(product_name == "Pink Lady Apple" | product_name == "Coffee Ice Cream") %>%
   mutate(order_dow = recode(order_dow, "0" = "Mon", 
                                "1" = "Tues", 
                                "2" = "Weds", 
                                "3" = "Thurs", 
                                "4" = "Fri", 
                                "5" = "Sat",
                                "6" = "Sun")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour_of_day = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour_of_day) %>%
    select("Mon", "Tues", "Weds", "Thurs", "Fri", "Sat", "Sun") %>%
  knitr::kable(digits = 1)
```

##Question 2
```{r}
data("brfss_smart2010") 

#rename dataset and clean names/data
brfss =
  janitor::clean_names(brfss_smart2010)  %>%
  filter(topic == "Overall Health") %>% 
  mutate(
    as.factor(response)
  ) %>%
  arrange(response, "Excellent", "Very Good", "Good", "Fair", "Poor") %>%
  fct_reorder(response)

#HOW TO ARRANGE#%>%
 # arrange(response, "Excellent", "Very Good", "Good", "Fair", "Poor")

```

#States observed at 7 or more locations
```{r}
#states with 7 or more testing locations in 2002
brfss %>% 
  filter(year == "2002") %>%
  group_by(locationabbr) %>%
  distinct(locationdesc) %>%
  summarize(total_testing_location = n()) %>%
  filter(total_testing_location >= 7) %>%
  arrange(total_testing_location) %>%
  knitr::kable(digits = 1)

#states with 7 or more testing locations in 2010
brfss %>% 
  filter(year == "2010") %>%
  group_by(locationabbr) %>%
  distinct(locationdesc) %>%
  summarize(total_testing_location = n()) %>%
  filter(total_testing_location >= 7) %>%
  arrange(total_testing_location) %>%
  knitr::kable(digits = 1)
```

#Excellent Data in 
```{r}
Excellent =
brfss %>% 
  filter(response == "Excellent") %>%
  group_by(locationabbr) %>%
  mutate(mean_data_value = mean(data_value, na.rm = TRUE)) %>%
  select(year, locationabbr, mean_data_value) %>%
  distinct(locationabbr, year, mean_data_value) %>%
  pivot_wider(
    names_from = year, 
    values_from = mean_data_value
  )

Excellent %>%
  group_by(locationabbr) %>%
  ggplot(aes(x = year, y = mean_data_value, color = locationabbr)) + 
  geom_line() 
```

#dual plot of 2006 and mean_data_value vs response
```{r}
dual_plot = 
  brfss %>%
  filter(year == "2006" | year == "2010",
         locationabbr == "NY") %>%
  group_by(year, response) %>%
  summarize(mean_data_value = mean(data_value, na.rm = TRUE)) 

dual_plot %>%
  ggplot(aes(x = response, y = mean_data_value)) +
  geom_col() +
  facet_wrap(~year)

```


##Question 3
```{r}
#read in data file
accel = read.csv(file = "./data/accel_data.csv")

accel_tidy = 
  janitor::clean_names(accel) %>%
  mutate(weekend = if_else(day == "Saturday" | day == "Sunday", "weekend", "weekday")) %>%
  pivot_longer(
    activity_1:activity_1440, 
    names_to = "activity", 
    values_to = "activity_counts"
  ) 
  
###col_types = "ddcccd"
```

#aggregate across a day to create total activity variable
```{r}
daily_accel_tidy =
  accel_tidy %>%
  group_by(day_id) %>%
  mutate(total_activity = sum(activity_counts)) %>%
  distinct(total_activity) %>%
  select(day_id, total_activity)

daily_accel_tidy %>%
  ggplot(aes(x = day_id, y = total_activity)) +
  geom_point() +
  geom_smooth()
```

#create plot to show fluctuation over each day
##FIX THIS
```{r}
accel_tidy %>%
  group_by(day_id) %>%
  mutate(as.numeric(activity)) %>%
  ggplot(aes(x = activity, y = activity_counts, color = day_id)) +
   geom_point() 
```

##Unused code
  arrange(desc(rank)) %>%
  fct_reorder(product_name, ranking)
  pivot_wider(
    names_from = product_name, 
    values_from = n_obs
  ) %>%